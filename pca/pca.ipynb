{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this Jupyter Notebook there is the application of PCA over \n",
    "the \"Pizza's Components\" dataset.\n",
    "The canonical representation of a dataset is the following.<br>\n",
    "It is a datamatrix $X \\in R^{n \\times p}$ where: <br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}n$ is the number of samples<br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}p$ is the number of the features\n",
    "\n",
    "On the rows there are samples while on the columns there are features:<br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm} x_{i} \\in R^{p} \\rightarrow$ each sample is a vector in a $p$-dimensional space <br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm} p_{j} \\in R^{n} \\rightarrow$ each feature is a vector in a $n$-dimensional space <br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import funcs\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn import datasets\n",
    "print(\"Pandas Version: {}\".format(pd.__version__))\n",
    "print(\"Numpy Version: {}\".format(np.__version__))\n",
    "print(\"Matplotlib Version: {}\".format(matplotlib.__version__))\n",
    "print(\"Scikit-learn Version: {}\".format(sklearn.__version__))\n",
    "print(\"Seaborn Version: {}\".format(sns.__version__))\n",
    "np.set_printoptions(suppress=True, linewidth=130)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T15:10:57.928379Z",
     "start_time": "2024-05-18T15:10:57.923288Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now it will be loaded the dataset about pizza different components",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataframe = pd.read_csv(\"D:\\\\Placement\\\\ML_Project\\\\dataset\\\\pca_pizza.csv\")\n",
    "n = np.shape(dataframe)[0]\n",
    "p = np.shape(dataframe)[1]\n",
    "print(\"Shape of Dataset: {}\\n\\t* Number of samples:\\t{}\\n\\t* Number of features:\\t{}\"\n",
    "      .format(np.shape(dataframe), n, p))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T14:51:51.960810Z",
     "start_time": "2024-05-18T14:51:51.949261Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a first inspection about<br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}$ Type of columns<br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}$ Missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(funcs.InfoColumns(dataframe))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are some statistics useful to steer the whole analysis:<br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}$ Descriptive statistics <br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}$ Skewness <br>\n",
    "$\\hspace{1cm}\\bullet \\hspace{0.5cm}$ Kurtosis <br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print(dataframe.describe(include='all'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(dataframe.drop(['brand','id'], axis=1).skew(axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(\"\\n\",dataframe.drop(['brand','id'], axis=1).kurtosis(axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "dataframe.drop(['brand','id'], axis=1).boxplot(figsize=(10,6))\n",
    "plt.savefig(\"D:\\\\Placement\\\\ML_Project\\\\plots\\\\pca_box_plot.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T14:56:15.784350Z",
     "start_time": "2024-05-18T14:56:15.551430Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "scatter = sns.pairplot(data=dataframe.drop(['id'], axis=1), markers='o')\n",
    "scatter.savefig(\"D:\\\\Placement\\\\ML_Project\\\\plots\\\\scatters.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T14:57:04.336385Z",
     "start_time": "2024-05-18T14:56:55.167271Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it will computed the centered version of the dataset.<br>\n",
    "***\n",
    "What does it means?<br>\n",
    "***\n",
    "In this way, it's performed a shift from the original canonical axis into the center of the distribution of the \n",
    "dataset.<br>\n",
    "It's computed an approximation which allows to discuss about the linear relationships (if exist) among features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this specific case it has been dropped the columns about brand and id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = dataframe.drop(['brand', 'id'], axis=1).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T14:58:31.078462Z",
     "start_time": "2024-05-18T14:58:31.074086Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Xc = X - np.mean(X, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-18T14:58:32.249611Z",
     "start_time": "2024-05-18T14:58:32.246095Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now there are two different strategies: <br>\n",
    "***\n",
    "PCA over the Covariance Matrix $C_{X_{C}}$<br> \n",
    "if the variances respect the order of importance that we want to attribute to the variables (it's defined a hierarchy \n",
    "based on relevance)<br>\n",
    "PCA over the Correlation Matrix $R_{X_{C}}$ <br>\n",
    "if we want to attribute the same importance to all the variables<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "HOW CAN WE CHOOSE WHAT MATRIX TO USE?\n",
    "***\n",
    "It must be computed some statistical measures over the original dataset (this is a multivariate case, since $p>1$) and \n",
    "check what is the variance of each feature.<br>\n",
    "In particular, if there is an high difference among variances, due to different measurement units, then it is \n",
    "recommended to compute the Correlation Matrix.\n",
    "***\n",
    "NB:: If the centered matrix $X_{C}$ is standardized, then $\\implies (C_{X_{C}} = R_{X_{C}})$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it will be computed both the Covariance Matrix $C_{X_{C}}$ and the Correlation Matrix $R_{X_{C}}$ on the \n",
    "transpose of the centered dataset $C_{{(X)}^{T}}$, because the goal of this analysis is find, if exist, \n",
    "some relations among features and not samples.\n",
    "***\n",
    "(NB) Computing the Covariance matrix on the centered dataset is equivalent to compute it on the original ones\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T15:11:22.707728Z",
     "start_time": "2024-05-18T15:11:22.701166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Covariance Matrix Image \n",
    "Image(\"D:\\\\Placement\\\\ML_Project\\\\images\\\\  covariance_matrix.png\")"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "Cov_Xc = np.cov(Xc.T)\n",
    "print(\"This is the Covariance Matrix C of the Transpose Centered Dataset:\\n\\n{}\"\n",
    "      .format(np.array_str(Cov_Xc)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T15:15:58.306818Z",
     "start_time": "2024-05-18T15:15:58.301584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Covariance Matrix Image \n",
    "Image(\"D:\\\\Placement\\\\ML_Project\\\\images\\\\correlation_cofficient.png\")"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "Corr_Xc = np.corrcoef(Xc.T)\n",
    "print(\"This is the Correlation Matrix R of the Transpose Centered Dataset:\\n\\n{}\"\n",
    "      .format(np.array_str(Corr_Xc)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then it will be computed the eigenvalues and eigenvectors of both matrices."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "eigenvalues_covariance, eigenvectors_covariance = np.linalg.eig(Cov_Xc)\n",
    "print(\"These are the eigenvalues of Covariance Matrix C:\\n{}\\n\".format(np.array_str(eigenvalues_covariance)))\n",
    "print(\"These are the eigenvectors of the Covariance Matrix C:\\n{}\".format(np.array_str(eigenvectors_covariance)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "eigenvalues_correlation, eigenvectors_correlation = np.linalg.eig(Corr_Xc)\n",
    "print(\"These are the eigenvalues of Correlation Matrix R:\\n{}\\n\".format(np.array_str(eigenvalues_correlation)))\n",
    "print(\"These are the eigenvectors of the Correlation Matrix R:\\n{}\".format(np.array_str(eigenvectors_correlation)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix of eigenvectors (for C and R) represent the rotation matrix $A_{p}$ such that:<br>\n",
    "$Y = X \\cdot A_{p}$ where \n",
    "\\begin{cases}\n",
    "\\bullet \\hspace{0.5cm} Y \\in R^{n \\times p} \\rightarrow \\text{ this is the matrix of scores (PC's)}\\\\\n",
    "\\bullet \\hspace{0.5cm} X \\in R^{n \\times p}  \\rightarrow \\text{ this is the original matrix}\\\\\n",
    "\\bullet \\hspace{0.5cm} A_{p} \\in R^{p \\times p}  \\rightarrow \\text{this is the matrix of loadings}\n",
    "\\end{cases} <br>\n",
    "The matrix $A_{p}$ rotates original data into the direction of maximum variance of the dataset and is useful to:<br>\n",
    "$\\hspace{1cm} 1. \\hspace{0.5cm}$ Perform a feature selection of the original variables<br>\n",
    "$\\hspace{1cm} 2. \\hspace{0.5cm}$ Gives Interpretation of the PC's <br>\n",
    "$\\hspace{2.3cm} (\\bullet) \\hspace{0.5cm}$in terms of magnitude of absolute values of axis<br>\n",
    "$\\hspace{2.3cm} (\\bullet) \\hspace{0.5cm}$using the correlation coefficients among PC's and original features $X_{i}$<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's consider the matrix $A_{p}$ related to the Covariance Matrix $C$\n",
    "In the column 1, the max absolute value is situated in position 6.<br>\n",
    "Hence, the feature 'Carboydrates' is going to be relevant for the construction of $Y_{1}$<br><br>\n",
    "In the column 2, the max absolute value is situated in position 1.<br>\n",
    "Hence, the feature 'Mois' is going to be relevant for the construction of $Y_{2}$<br><br>\n",
    "In the column 3, the max absolute value is situated in position 2.<br>\n",
    "Hence, the feature 'Fat' is going to be relevant for the construction of $Y_{3}$<br><br>\n",
    "In the column 4, the max absolute value is situated in position 4.<br>\n",
    "Hence, the feature 'Ash' is going to be relevant for the construction of $Y_{4}$<br><br>\n",
    "In the column 5, the max absolute value is situated in position 5.<br>\n",
    "Hence, the feature 'Sodium' is going to be relevant for the construction of $Y_{5}$<br><br>\n",
    "In the column 6, the max absolute value is situated in position 4.<br>\n",
    "Hence, the feature 'Ash' is going to be relevant for the construction of $Y_{6}$<br><br>\n",
    "In the column 7, the max absolute value is situated in position 7.<br>\n",
    "Hence, the feature 'Calories' is going to be relevant for the construction of $Y_{7}$\n",
    "***\n",
    "### Let's consider the matrix $A_{p}$ related to the Correlation Matrix $R$<br><br>\n",
    "In the column 1, the max absolute value is situated in position 4.<br>\n",
    "Hence, the feature 'Ash' is going to be relevant for the construction of $Y_{1}$<br><br>\n",
    "In the column 2, the max absolute value is situated in position 1.<br>\n",
    "Hence, the feature 'Mois' is going to be relevant for the construction of $Y_{2}$<br><br>\n",
    "In the column 3, the max absolute value is situated in position 2.<br>\n",
    "Hence, the feature 'Protein' is going to be relevant for the construction of $Y_{3}$<br><br>\n",
    "In the column 4, the max absolute value is situated in position 4.<br>\n",
    "Hence, the feature 'Ash' is going to be relevant for the construction of $Y_{4}$<br><br>\n",
    "In the column 5, the max absolute value is situated in position 4.<br>\n",
    "Hence, the feature 'Ash' is going to be relevant for the construction of $Y_{5}$<br><br>\n",
    "In the column 6, the max absolute value is situated in position 7.<br>\n",
    "Hence, the feature 'Calories' is going to be relevant for the construction of $Y_{6}$<br><br>\n",
    "In the column 7, the max absolute value is situated in position 6.<br>\n",
    "Hence, the feature 'Carboydrates' is going to be relevant for the construction of $Y_{7}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it can be computed the matrix $Y$ (hence, the principal components), and it can be defined also a semantic for \n",
    "the new features (PC's) through by the study of correlations among original features $X_{i}$ and \n",
    "principal components $Y_{j}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "YC = Xc.dot(eigenvectors_covariance)\n",
    "print(\"This is the dimension of the Y matrix \\t {}\\n\\t(*) using the loadings of the covariance matrix C\\n\"\n",
    "      \"\\t(*) It must be equal to the dimension of the original dataset\\n\".format(np.shape(YC)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "YR = Xc.dot(eigenvectors_correlation)\n",
    "print(\"This is the dimension of the Y matrix \\t {}\\n\\t(*) using the loadings of the correlation matrix R\\n\"\n",
    "      \"\\t(*) It must be equal to the dimension of the original dataset\".format(np.shape(YR)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's shown the Scree-Plot, useful to choose what is the number of components $(k)$\n",
    "that is better to retained in order to account for most of the variation in the dataset. <br>\n",
    "The number $k$ has been computed using the Cumulative Percentage of Total Variation.<br> \n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}C \\rightarrow t_{k} = 100 \\cdot \\frac{\\sum_{i=1}^{k}\\lambda_{i}}{\\sum_{i=1}^{p}\\lambda_{i}} = \n",
    "100 \\cdot \\frac{\\sum_{i=1}^{k}\\lambda_{i}}{trace(C_{X})}$<br><br>\n",
    "\n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}R \\rightarrow t_{k} = 100 \\cdot \\frac{\\sum_{i=1}^{k}\\lambda_{i}}{p}$<br><br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "total_variation_covariance = np.sum(eigenvalues_covariance)\n",
    "explained_variance_covariance = np.asarray(\n",
    "    [100*(i/total_variation_covariance) for i in sorted(eigenvalues_covariance, reverse=True)])\n",
    "print(\"This is the explained variance of each feature (covariance):\\n\\t{}\"\n",
    "      .format(np.array_str(explained_variance_covariance, precision=2)))\n",
    "cumulative_covariance = np.cumsum(explained_variance_covariance)\n",
    "print(\"This is the cumulative variance (covariance):\\n\\t{}\"\n",
    "      .format(np.array_str(cumulative_covariance, precision=2)))\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(10,6))\n",
    "plt.title(\"Scree plots of Covariance Matrix\")\n",
    "plt.bar(x=np.arange(np.shape(explained_variance_covariance)[0]), \n",
    "        height=explained_variance_covariance, \n",
    "        width=0.4, color=\"green\")\n",
    "plt.plot(np.arange(np.shape(explained_variance_covariance)[0]), \n",
    "         explained_variance_covariance, \n",
    "         linestyle=\"--\", marker=\"o\", markersize=15,\n",
    "         color=\"red\", label=\"explained variance (covariance)\")\n",
    "plt.savefig(\"images/screeplot_covariance_pizza.png\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "total_variation_correlation = np.sum(eigenvalues_correlation)\n",
    "explained_variance_correlation = np.asarray(\n",
    "    [100*(i/total_variation_correlation) for i in sorted(eigenvalues_correlation, reverse=True)])\n",
    "print(\"This is the explained variance of each feature (correlation):\\n\\t{}\"\n",
    "      .format(np.array_str(explained_variance_correlation, precision=2)))\n",
    "cumulative_correlation = np.cumsum(explained_variance_correlation)\n",
    "print(\"This is the cumulative variance (correlation):\\n\\t{}\"\n",
    "      .format(np.array_str(cumulative_correlation, precision=2)))\n",
    "\n",
    "fig2 = plt.figure(2, figsize=(10,6))\n",
    "plt.title(\"Scree plots of Correlation Matrices\")\n",
    "plt.bar(x=np.arange(np.shape(explained_variance_correlation)[0]), \n",
    "        height=explained_variance_correlation, \n",
    "        width=0.4, color=\"green\")\n",
    "plt.plot(np.arange(np.shape(explained_variance_correlation)[0]), \n",
    "         explained_variance_correlation, \n",
    "         linestyle=\"--\", marker=\"o\", markersize=15,\n",
    "         color=\"red\", label=\"explained variance correlation\")\n",
    "plt.savefig(\"images/screeplot_correlation_pizza.png\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "number_k = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation circle (Original features and PC's of the covariance matrix C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "CC_Covariance = []\n",
    "for i in range(np.shape(X)[1]):\n",
    "    f = []\n",
    "    for j in range(np.shape(YC)[1]):\n",
    "        c = (np.corrcoef(X[:,i], YC[:,j])[0])[1]\n",
    "        f.append(c)\n",
    "    CC_Covariance.append(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "CorrelationCircle_Covariance = np.asarray(CC_Covariance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "print(\"This is the full Correlation Matrix (based on C):\\n{}\"\n",
    "      .format(CorrelationCircle_Covariance))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "print(\"This is the Correlation Matrix with {} PC's (based on C):\\n{}\"\n",
    "      .format(number_k, CorrelationCircle_Covariance[:,0:number_k]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "fig3 = plt.figure(figsize=(8,8))\n",
    "plt.title(\"Correlation Cirle \\nFeatures vs PC's (Covariance matrix C)\")\n",
    "plt.hlines(y=0, xmin=-1, xmax=1, colors='black', linewidth=4, linestyle='solid')\n",
    "plt.vlines(x=0, ymin=-1, ymax=1, colors='black', linewidth=4, linestyle='solid')\n",
    "for i in range(0,np.shape(X)[1]):\n",
    "    plt.scatter(CorrelationCircle_Covariance[i:i+1,0:1], \n",
    "                CorrelationCircle_Covariance[i:i+1,1:2], s=300, label=dataframe.columns[i+2])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.xlim(-1.1,1.1)\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), \n",
    "           fancybox=True, ncol=np.shape(X)[1])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/circle_correlation_covariance_pizza.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation circle (Original features and PC's of the correlation matrix R)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "CC_Correlation = []\n",
    "for i in range(np.shape(X)[1]):\n",
    "    f = []\n",
    "    for j in range(np.shape(YR)[1]):\n",
    "        c = (np.corrcoef(X[:,i], YR[:,j])[0])[1]\n",
    "        f.append(c)\n",
    "    CC_Correlation.append(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "CorrelationCircle_Correlation = np.asarray(CC_Correlation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "print(\"This is the full Correlation Matrix (based on R):\\n{}\"\n",
    "      .format(CorrelationCircle_Correlation))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "print(\"This is the Correlation Matrix with {} PC's (based on R):\\n{}\"\n",
    "      .format(number_k, CorrelationCircle_Correlation[:,0:number_k]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "fig4 = plt.figure(figsize=(8,8))\n",
    "plt.title(\"Correlation Cirle \\nFeatures vs PC's (Correlation matrix R)\")\n",
    "plt.hlines(y=0, xmin=-1, xmax=1, colors='black', linewidth=4, linestyle='solid')\n",
    "plt.vlines(x=0, ymin=-1, ymax=1, colors='black', linewidth=4, linestyle='solid')\n",
    "for i in range(0,np.shape(X)[1]):\n",
    "    plt.scatter(CorrelationCircle_Correlation[i:i+1,0:1], \n",
    "                CorrelationCircle_Correlation[i:i+1,1:2], \n",
    "                s=300, label=dataframe.columns[i+2])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.xlim(-1.1,1.1)\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), \n",
    "           fancybox=True,ncol=np.shape(X)[1])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/circle_correlation_correlation_pizza.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "### Covariance Matrix \n",
    "Using the Covariance matrix $C_{X}$ to perform PCA and choose a $k = 2$ (qualitative analysis) which is the number \n",
    "of components that retains $\\sim 97\\%$ of total information embedded in the dataset, it can be found that:<br>\n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}$ PC1 is an index of energy supply (Protein(2) + Ash(4) + Carbohydrates(6))<br>\n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}$ PC2 is an index of the heaviness of pizza (Calories(7))\n",
    "\n",
    "### Correlation Matrix \n",
    "Using the Correlation matrix $R_{X}$ to perform PCA and choose a $k = 2$ (qualitative analysis) which is the number \n",
    "of components that retains $\\sim 92\\%$ of total information embedded in the dataset, it can be found that:<br>\n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}$ PC1 is an index of energy supply (Protein(2) + Ash(4) + Carbohydrates(6))<br>\n",
    "$\\hspace{1cm}(\\bullet)\\hspace{0.3cm}$ PC2 is an index of tastiness of dough's consistency (mois(1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
